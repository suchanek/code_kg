# CodeKG Architecture

**CodeKG v0** â€” A Deterministic Knowledge Graph for Python Codebases
with Semantic Indexing and Source-Grounded Snippet Packing

*Author: Eric G. Suchanek, PhD*

---

## Overview

CodeKG constructs a deterministic, explainable knowledge graph from a Python codebase using static analysis. The graph captures structural relationships â€” definitions, calls, imports, and inheritance â€” directly from the Python AST, stores them in SQLite, and augments retrieval with vector embeddings via LanceDB.

Structure is treated as **ground truth**. Semantic search is strictly an acceleration layer. Every node and edge maps to a concrete file and line number.

The system ships with:
- A **Python library** (`code_kg`) with a layered class API
- **CLI entry points** for building and querying the graph
- A **Streamlit web application** (`app.py`) for interactive exploration
- A **Docker image** for zero-install deployment
- An **MCP server** (`codekg-mcp`) for AI agent integration
- A **`/setup-mcp` Claude skill** for automated MCP configuration

---

## Design Principles

1. **Structure is authoritative** â€” The AST-derived graph is the source of truth.
2. **Semantics accelerate, never decide** â€” Vector embeddings seed and rank retrieval but never invent structure.
3. **Everything is traceable** â€” Nodes and edges map to concrete files and line numbers.
4. **Determinism over heuristics** â€” Identical input yields identical output.
5. **Composable artifacts** â€” SQLite for structure, LanceDB for vectors, Markdown/JSON for consumption.

---

## Layered Class Architecture

The system is organized into four focused layers, each independently testable and composable:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CodeKG                             â”‚
â”‚              (orchestrator â€” kg.py)                     â”‚
â”‚                                                         â”‚
â”‚  build()  build_graph()  build_index()                  â”‚
â”‚  query()  pack()  stats()  node()                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚
         â–¼              â–¼              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ CodeGraph  â”‚ â”‚ GraphStore â”‚ â”‚  SemanticIndex   â”‚
  â”‚ (graph.py) â”‚ â”‚ (store.py) â”‚ â”‚   (index.py)     â”‚
  â”‚            â”‚ â”‚            â”‚ â”‚                  â”‚
  â”‚ Pure AST   â”‚ â”‚  SQLite    â”‚ â”‚  LanceDB +       â”‚
  â”‚ extraction â”‚ â”‚ canonical  â”‚ â”‚  Embedder        â”‚
  â”‚ No I/O     â”‚ â”‚ store      â”‚ â”‚  (disposable)    â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  codekg.py â”‚
  â”‚ (primitivesâ”‚
  â”‚  locked v0)â”‚
  â”‚ Node, Edge â”‚
  â”‚ extract_   â”‚
  â”‚   repo()   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer 1 â€” Primitives (`codekg.py`)

The locked v0 contract. Pure, deterministic, side-effect free.

- **`Node`** â€” frozen dataclass: `id`, `kind`, `name`, `qualname`, `module_path`, `lineno`, `end_lineno`, `docstring`
- **`Edge`** â€” frozen dataclass: `src`, `rel`, `dst`, `evidence`
- **`extract_repo(repo_root)`** â€” walks all `.py` files, runs two AST passes (definitions + call graph), returns `(nodes, edges)`

Node kinds: `module`, `class`, `function`, `method`, `symbol`
Edge relations: `CONTAINS`, `CALLS`, `IMPORTS`, `INHERITS`

### Layer 2 â€” `CodeGraph` (`graph.py`)

Pure AST extraction with a clean object interface. No I/O, no persistence.

```python
graph = CodeGraph("/path/to/repo")
graph.extract()          # cached; force=True to re-run
nodes = graph.nodes      # List[Node]
edges = graph.edges      # List[Edge]
nodes, edges = graph.result()
print(graph.stats())     # node/edge counts by kind
```

- Lazy extraction â€” `.nodes` and `.edges` trigger `extract()` automatically
- `extract(force=True)` re-runs from scratch
- `stats()` returns counts by kind/relation plus `repo_root`

### Layer 3 â€” `GraphStore` (`store.py`)

SQLite-backed authoritative store. No embeddings, no AST.

```python
store = GraphStore("codekg.sqlite")
store.write(nodes, edges, wipe=True)   # persist graph
n = store.node("fn:src/foo.py:bar")    # fetch by id
nodes = store.query_nodes(kinds=["function", "method"])
edges = store.edges_within(node_id_set)
meta  = store.expand(seed_ids, hop=2)  # â†’ Dict[str, ProvMeta]
print(store.stats())
```

Key methods:

| Method | Description |
|---|---|
| `write(nodes, edges, wipe=False)` | Persist a complete graph (upsert) |
| `clear()` | Delete all nodes and edges |
| `node(id)` | Fetch a single node dict by ID |
| `query_nodes(kinds=, module=)` | Filtered node list |
| `edges_within(node_ids)` | Edges with both endpoints in the set |
| `expand(seed_ids, hop=1, rels=â€¦)` | BFS expansion with `ProvMeta` provenance |
| `stats()` | Node/edge counts by kind/relation |

**`ProvMeta`** â€” returned by `expand()`:
- `best_hop` â€” minimum hop distance from any seed
- `via_seed` â€” ID of the seed that yielded the shortest path

Supports context manager (`with GraphStore(...) as store:`).

### Layer 4 â€” `SemanticIndex` (`index.py`)

LanceDB-backed vector index. Derived from SQLite; disposable and rebuildable.

```python
embedder = SentenceTransformerEmbedder("all-MiniLM-L6-v2")
idx = SemanticIndex("./lancedb", embedder=embedder)
idx.build(store, wipe=True)            # embed nodes â†’ LanceDB
hits = idx.search("database setup", k=8)  # â†’ List[SeedHit]
```

**`Embedder`** â€” abstract base class with pluggable backends:
- `embed_texts(texts)` â†’ `List[List[float]]`
- `embed_query(query)` â†’ `List[float]` (default: calls `embed_texts`)

**`SentenceTransformerEmbedder`** â€” default implementation using `sentence-transformers`.

**`SeedHit`** â€” dataclass returned by `search()`:
- `id`, `kind`, `name`, `qualname`, `module_path`, `distance`, `rank`

Index text format (stable â€” changing invalidates the index):
```
KIND: function
NAME: connect_db
QUALNAME: DatabaseManager.connect_db
MODULE: src/db/manager.py
LINE: 42
DOCSTRING:
Establish a connection to the database.
```

---

## Orchestrator â€” `CodeKG` (`kg.py`)

The top-level entry point. Owns all four layers with lazy initialization.

```python
kg = CodeKG(
    repo_root="/path/to/repo",
    db_path="codekg.sqlite",
    lancedb_dir="./lancedb",
    model="all-MiniLM-L6-v2",   # optional
    table="codekg_nodes",        # optional
)

# Full pipeline
stats = kg.build(wipe=True)

# Graph only (no embedding)
stats = kg.build_graph(wipe=True)

# Index only (graph must exist)
stats = kg.build_index(wipe=True)

# Hybrid query
result = kg.query("database connection setup", k=8, hop=1)
result.print_summary()

# Snippet pack
pack = kg.pack("configuration loading", k=8, hop=1)
pack.save("context.md")          # or fmt="json"

# Convenience
kg.stats()                       # store stats
kg.node("fn:src/foo.py:bar")     # fetch node
```

Layer properties are lazy â€” the embedder and LanceDB connection are only created when first needed.

Supports context manager (`with CodeKG(...) as kg:`).

---

## Result Types (`kg.py`)

### `BuildStats`

Returned by `build()`, `build_graph()`, `build_index()`.

| Field | Type | Description |
|---|---|---|
| `repo_root` | `str` | Repository root |
| `db_path` | `str` | SQLite path |
| `total_nodes` | `int` | Total nodes in store |
| `total_edges` | `int` | Total edges in store |
| `node_counts` | `dict` | Counts by kind |
| `edge_counts` | `dict` | Counts by relation |
| `indexed_rows` | `int?` | Vectors indexed (None if not built) |
| `index_dim` | `int?` | Embedding dimension |

Methods: `to_dict()`, `__str__()`

### `QueryResult`

Returned by `kg.query()`.

| Field | Description |
|---|---|
| `query` | Original query string |
| `seeds` | Number of semantic seed nodes |
| `expanded_nodes` | Total nodes after graph expansion |
| `returned_nodes` | Nodes after symbol filtering |
| `hop` | Hop count used |
| `rels` | Edge types used |
| `nodes` | List of node dicts, sorted by rank |
| `edges` | Edges within the returned node set |

Methods: `to_dict()`, `to_json()`, `print_summary()`

### `SnippetPack`

Returned by `kg.pack()`. Extends `QueryResult` with source snippets.

Each node dict may contain a `snippet` key:
```json
{
  "path": "src/db/manager.py",
  "start": 40,
  "end": 55,
  "text": "   40: def connect_db(self):\n   41:     ..."
}
```

Methods: `to_dict()`, `to_json()`, `to_markdown()`, `save(path, fmt="md")`

---

## Build Pipeline

### Phase 1 â€” Static Analysis (AST â†’ SQLite)

`CodeGraph.extract()` â†’ `GraphStore.write()`

- Walk all `.py` files (skipping `.venv`, `__pycache__`, `.git`, etc.)
- **Pass 1**: extract modules, classes, functions, methods, imports, inheritance
- **Pass 2**: extract call graph (best-effort, honest â€” unresolved calls become `sym:` nodes)
- Generate stable, deterministic node IDs: `mod:`, `cls:`, `fn:`, `m:`, `sym:`
- Emit edges with evidence (`lineno`, `expr`)
- Persist to SQLite via upsert (idempotent)

**No embeddings. No LLMs.**

### Phase 2 â€” Semantic Indexing (SQLite â†’ LanceDB)

`SemanticIndex.build(store)`

- Read `module`, `class`, `function`, `method` nodes from SQLite
- Build canonical index text (name + qualname + module + docstring)
- Embed in batches using `SentenceTransformerEmbedder`
- Upsert into LanceDB (delete-then-add per batch)

The vector index is **derived and disposable** â€” it can be rebuilt from SQLite at any time.

---

## Hybrid Query Model

`CodeKG.query()` and `CodeKG.pack()` execute in two phases:

### Phase 1 â€” Semantic Seeding

```
query string â†’ embed â†’ vector search â†’ top-K SeedHit list
```

Each `SeedHit` carries `id`, `distance`, and `rank`.

### Phase 2 â€” Structural Expansion

```
seed_ids â†’ GraphStore.expand(hop=N, rels=â€¦) â†’ Dict[node_id, ProvMeta]
```

BFS traversal over `CONTAINS`, `CALLS`, `IMPORTS`, `INHERITS` edges. Each reachable node records:
- `best_hop` â€” minimum distance from any seed
- `via_seed` â€” which seed yielded the shortest path

---

## Ranking and Deduplication

Nodes are ranked deterministically by a composite key:

```
(best_hop, seed_distance, kind_priority, node_id)
```

Kind priority: `function=0`, `method=1`, `class=2`, `module=3`, `symbol=4`

Deduplication (in `pack()` only):
- Compute source span `(start_line, end_line)` for each node
- Skip nodes whose span overlaps (within a 2-line gap) an already-kept span in the same file
- Cap total returned nodes at `max_nodes` (default 50)

---

## Snippet Extraction

For each retained node, `pack()` extracts a source-grounded snippet:

1. Resolve `module_path` â†’ absolute path via `_safe_join()` (path-traversal safe)
2. Read file lines (cached per file)
3. Compute span: AST `lineno`/`end_lineno` Â± `context` lines, capped at `max_lines`
4. Emit line-numbered text block

Module nodes show the top-of-file window. Nodes without line info fall back to the top window.

---

## Streamlit Web Application (`app.py`)

CodeKG ships an interactive knowledge-graph explorer built with **Streamlit** and **pyvis**.

```bash
# Launch locally
codekg-viz [--db codekg.sqlite] [--port 8501]

# Or directly
streamlit run app.py
```

The application provides three tabs:

| Tab | Description |
|---|---|
| **ğŸ—ºï¸ Graph Browser** | Interactive pyvis graph of the full knowledge graph; filter by node kind or module path; click nodes for rich detail panels |
| **ğŸ” Hybrid Query** | Natural-language query â†’ semantic seeds â†’ graph expansion â†’ ranked node results with graph, table, edge, and JSON views |
| **ğŸ“¦ Snippet Pack** | Query â†’ source-grounded code snippets with download buttons for Markdown and JSON |

The sidebar exposes all build and query controls:
- **Build Graph** â€” AST extraction â†’ SQLite (fast, no embeddings)
- **Build Index** â€” embed nodes â†’ LanceDB
- **Build All** â€” full pipeline in one click

The app reads `CODEKG_DB` and `CODEKG_LANCEDB` environment variables so the Docker image works out of the box without manual path configuration.

---

## Docker Image

CodeKG ships a Docker image that packages the Streamlit app with all heavy dependencies (`sentence-transformers`, `lancedb`, `pyvis`, `torch`) into a single portable container.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Host machine                                           â”‚
â”‚                                                         â”‚
â”‚  /path/to/repo  â”€â”€(read-only)â”€â”€â–¶  /workspace  â”        â”‚
â”‚                                                â”‚        â”‚
â”‚  Docker volume codekg-data â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚    /data/codekg.sqlite                         â”‚        â”‚
â”‚    /data/lancedb/                              â”‚        â”‚
â”‚                                                â”‚        â”‚
â”‚  localhost:8501 â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quick Start

```bash
# Build
docker build -t codekg:latest .

# Run (analyse current directory)
docker run -p 8501:8501 \
  -v $(pwd):/workspace:ro \
  -v codekg-data:/data \
  codekg:latest
```

Open **http://localhost:8501** in your browser.

### Docker Compose (recommended)

```bash
# Start (build if needed, detached)
docker compose up -d

# Analyse a specific repo
REPO_ROOT=/path/to/your/repo docker compose up -d

# Use a different host port
CODEKG_PORT=8510 docker compose up -d

# Stop (volume preserved)
docker compose down

# Full reset (wipes graph data)
docker compose down -v
```

### Key Design Decisions

- **`python:3.11-slim`** base image â€” keeps the image small
- **Poetry 2.x** for reproducible dependency installation
- **Layer ordering** â€” `pyproject.toml`/`poetry.lock` copied before source files; source-only changes rebuild in seconds, not minutes
- **Named volume `codekg-data`** â€” SQLite graph and LanceDB index persist across container restarts
- **Read-only workspace mount** â€” the analysed repository is never modified

### Docker Files

| File | Purpose |
|---|---|
| `Dockerfile` | Image definition (python:3.11-slim + Poetry 2.x) |
| `docker-compose.yml` | Service orchestration with volumes, env vars, healthcheck |
| `.dockerignore` | Keeps build context lean |
| `.streamlit/config.toml` | Baked-in Streamlit server config (headless, dark theme) |

### Environment Variables

| Variable | Default (container) | Description |
|---|---|---|
| `CODEKG_DB` | `/data/codekg.sqlite` | SQLite knowledge graph path |
| `CODEKG_LANCEDB` | `/data/lancedb` | LanceDB vector index directory |
| `CODEKG_PORT` | `8501` | Host port (compose only) |
| `REPO_ROOT` | `./` | Host path mounted at `/workspace` (compose only) |

See `docs/docker.md` for the full Docker reference.

---

## MCP Server (`mcp_server.py`)

CodeKG ships a built-in **Model Context Protocol (MCP) server** that exposes the full hybrid query and snippet-pack pipeline as structured tools consumable by any MCP-compatible AI agent â€” Claude Desktop, Cursor, Continue, or any custom agent.

The server is a thin wrapper around `CodeKG`. It initialises a single `CodeKG` instance at startup and routes tool calls to it. All logic lives in the existing library; the MCP layer adds no logic of its own.

### Starting the Server

```bash
codekg-mcp \
  --repo    /path/to/repo \
  --db      /path/to/codekg.sqlite \
  --lancedb /path/to/lancedb
```

| Flag | Default | Description |
|---|---|---|
| `--repo` | `.` | Repository root (for snippet path resolution) |
| `--db` | `codekg.sqlite` | SQLite knowledge graph |
| `--lancedb` | `./lancedb` | LanceDB vector index directory |
| `--model` | `all-MiniLM-L6-v2` | Sentence-transformer embedding model |
| `--transport` | `stdio` | `stdio` (Claude Desktop) or `sse` (HTTP clients) |

### Prerequisites

The SQLite graph and LanceDB index must be built before starting the server:

```bash
codekg-build-sqlite --repo /path/to/repo --db codekg.sqlite
codekg-build-lancedb --db codekg.sqlite --lancedb ./lancedb
```

The `mcp` package is an optional dependency:

```bash
pip install "code-kg[mcp]"
# or
poetry add mcp
```

### Available Tools

| Tool | Description |
|---|---|
| `query_codebase(q, k, hop, rels, include_symbols)` | Hybrid semantic + structural query; returns ranked nodes and edges as JSON |
| `pack_snippets(q, k, hop, rels, include_symbols, context, max_lines, max_nodes)` | Hybrid query + source-grounded snippet extraction; returns Markdown |
| `get_node(node_id)` | Fetch a single node by its stable ID; returns JSON |
| `graph_stats()` | Node and edge counts by kind/relation; returns JSON |

### Configuring Claude Desktop

Add a `codekg` entry to `claude_desktop_config.json`
(macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`):

```json
{
  "mcpServers": {
    "codekg": {
      "command": "codekg-mcp",
      "args": [
        "--repo",    "/absolute/path/to/repo",
        "--db",      "/absolute/path/to/codekg.sqlite",
        "--lancedb", "/absolute/path/to/lancedb"
      ]
    }
  }
}
```

Use **absolute paths** â€” Claude Desktop does not inherit the shell's working directory.

### Configuring Claude Code (`.mcp.json`)

For Claude Code, use `poetry run` so the entry point resolves correctly:

```json
{
  "mcpServers": {
    "codekg": {
      "command": "poetry",
      "args": [
        "run", "codekg-mcp",
        "--repo",    "/path/to/repo",
        "--db",      "/path/to/codekg.sqlite",
        "--lancedb", "/path/to/lancedb"
      ]
    }
  }
}
```

### Transport Modes

| Mode | Use case |
|---|---|
| `stdio` (default) | Claude Desktop and local agent frameworks; protocol runs over stdin/stdout |
| `sse` | HTTP-based clients; server listens on a port and streams events |

### MCP Server Properties

- **Read-only** â€” the server never modifies the graph
- **Stateful** â€” one `CodeKG` instance per server process, shared across all tool calls
- **Lazy** â€” the embedder and LanceDB connection are only created on first use

See `docs/MCP.md` for the full MCP reference including query strategy guide, tool schemas, and troubleshooting.

---

## `/setup-mcp` Claude Skill

The repository ships a **Claude skill** at `.claude/commands/setup-mcp.md` that automates the full MCP setup workflow. Invoke it from Claude Code:

```
/setup-mcp [/path/to/repo]
```

The skill executes these steps in sequence:

1. **Resolve the target repository** â€” verifies the path contains Python files
2. **Verify CodeKG installation** â€” checks `codekg-mcp` is available; installs the `mcp` extra if needed
3. **Build the SQLite graph** â€” runs `codekg-build-sqlite`, reports node/edge counts
4. **Build the LanceDB index** â€” runs `codekg-build-lancedb`, reports vector count
5. **Smoke-test the pipeline** â€” runs `kg.stats()` and a sample query end-to-end
6. **Configure MCP clients** â€” writes/updates both `.mcp.json` (Claude Code) and `claude_desktop_config.json` (Claude Desktop) with correct absolute paths
7. **Final report** â€” summarises all steps and reminds the user to restart their agent

---

## CLI Entry Points

All six entry points are registered in `pyproject.toml`:

| Command | Module | Description |
|---|---|---|
| `codekg-build-sqlite` | `build_codekg_sqlite` | repo â†’ SQLite |
| `codekg-build-lancedb` | `build_codekg_lancedb` | SQLite â†’ LanceDB |
| `codekg-query` | `codekg_query` | hybrid query, text output |
| `codekg-pack` | `codekg_snippet_packer` | hybrid query + snippet pack |
| `codekg-viz` | `codekg_viz` | launch Streamlit visualizer |
| `codekg-mcp` | `mcp_server` | start MCP server |

Each CLI module is a thin wrapper that constructs the appropriate class(es) and delegates.

---

## Source Layout

```
code_kg/
â”œâ”€â”€ src/code_kg/
â”‚   â”œâ”€â”€ codekg.py                # Locked v0 primitives: Node, Edge, extract_repo
â”‚   â”œâ”€â”€ graph.py                 # CodeGraph â€” pure AST extraction
â”‚   â”œâ”€â”€ store.py                 # GraphStore â€” SQLite persistence + traversal
â”‚   â”œâ”€â”€ index.py                 # SemanticIndex, Embedder, SeedHit
â”‚   â”œâ”€â”€ kg.py                    # CodeKG orchestrator + BuildStats, QueryResult, SnippetPack
â”‚   â”œâ”€â”€ build_codekg_sqlite.py   # CLI: repo â†’ SQLite
â”‚   â”œâ”€â”€ build_codekg_lancedb.py  # CLI: SQLite â†’ LanceDB
â”‚   â”œâ”€â”€ codekg_query.py          # CLI: hybrid query
â”‚   â”œâ”€â”€ codekg_snippet_packer.py # CLI: snippet pack
â”‚   â”œâ”€â”€ codekg_viz.py            # CLI: launch Streamlit visualizer
â”‚   â””â”€â”€ mcp_server.py            # MCP server (FastMCP, optional dep)
â”œâ”€â”€ app.py                       # Streamlit web application
â”œâ”€â”€ Dockerfile                   # Docker image definition
â”œâ”€â”€ docker-compose.yml           # Docker Compose service
â”œâ”€â”€ .streamlit/config.toml       # Streamlit server config
â”œâ”€â”€ .mcp.json                    # Claude Code MCP configuration
â”œâ”€â”€ .claude/commands/setup-mcp.md # /setup-mcp Claude skill
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_primitives.py       # Node, Edge, extract_repo, helpers (40 tests)
â”‚   â”œâ”€â”€ test_graph.py            # CodeGraph (12 tests)
â”‚   â”œâ”€â”€ test_store.py            # GraphStore (18 tests)
â”‚   â””â”€â”€ test_kg.py               # CodeKG, result types, span utilities (28 tests)
â””â”€â”€ docs/
    â”œâ”€â”€ Architecture.md          # This document
    â”œâ”€â”€ MCP.md                   # MCP server reference
    â””â”€â”€ docker.md                # Docker setup reference
```

---

## Data Flow Summary

```
Repository (.py files)
        â”‚
        â–¼  CodeGraph.extract()
  (nodes, edges)          â† pure, deterministic, no I/O
        â”‚
        â–¼  GraphStore.write()
  codekg.sqlite           â† authoritative, canonical
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ nodes table â”‚
  â”‚ edges table â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼  SemanticIndex.build()
  lancedb_dir/            â† derived, disposable
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ codekg_nodes tbl â”‚
  â”‚ (id, vector, â€¦)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼  CodeKG.query() / .pack()
  semantic seeds (LanceDB)
        +
  structural expansion (SQLite)
        â”‚
        â–¼  rank + dedupe
  QueryResult / SnippetPack
        â”‚
        â–¼
  Markdown / JSON output
        â”‚
        â”œâ”€â”€â–¶  Streamlit app (app.py)     â† interactive browser
        â””â”€â”€â–¶  MCP server (mcp_server.py) â† AI agent tools
```

---

## Dependencies

| Package | Role |
|---|---|
| `lancedb â‰¥ 0.6.0` | Vector database for semantic index |
| `sentence-transformers â‰¥ 2.7.0` | Local embedding model |
| `numpy â‰¥ 1.24.0` | Vector arithmetic |
| `streamlit â‰¥ 1.35.0` | Web application framework |
| `pyvis â‰¥ 0.3.2` | Interactive graph visualization |
| `pandas â‰¥ 2.0.0` | Tabular data display in Streamlit |
| `mcp â‰¥ 1.0.0` *(optional)* | Model Context Protocol server |
| Python `ast` (stdlib) | AST parsing â€” no external dep |
| Python `sqlite3` (stdlib) | Relational graph store |

Python â‰¥ 3.10, < 3.13.

Install the MCP extra with:
```bash
pip install "code-kg[mcp]"
```
